{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbfa507",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c6affa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import dataloader as DL\n",
    "import layers as CLayers\n",
    "import train_utils as TU\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f5fb904",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf039d",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8a986f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/ADNI_saliency.csv', low_memory=False)\n",
    "date = '20240118_2300'\n",
    "input_name = 'MagGrad'\n",
    "timepoint = '2Y'\n",
    "df = df[df[f'CONV_STATE_{timepoint}'] != -1]\n",
    "unique_rids = df['RID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7c4009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_rids, valid_rids = train_test_split(unique_rids, test_size=0.2, random_state=2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540785b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(f'./data/train_rids_{timepoint}.txt', 'w') as file:\n",
    "#     for rid in train_rids:\n",
    "#         file.write(f\"{rid}\\n\")\n",
    "# with open(f'./data/val_rids_{timepoint}.txt', 'w') as file:\n",
    "#     for rid in valid_rids:\n",
    "#         file.write(f\"{rid}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021b6d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'./data/train_rids_{timepoint}.txt', 'r') as file:\n",
    "    train_rids = [line.strip() for line in file]\n",
    "train_rids = [int(float(rid)) for rid in train_rids]\n",
    "# Load validation RIDs from the text file\n",
    "with open(f'./data/val_rids_{timepoint}.txt', 'r') as file:\n",
    "    valid_rids = [line.strip() for line in file]\n",
    "valid_rids = [int(float(rid)) for rid in valid_rids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cd25f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = './data/ADNI_saliency.csv'\n",
    "batch_size  = 10\n",
    "num_classes = 3\n",
    "timesteps   = int(timepoint[0])*2+1\n",
    "image_shape = (84,48,42)\n",
    "use_pe = False\n",
    "augmented = True\n",
    "train_ds = DL.InputFunction(filepath    = data_file,\n",
    "                            list_rids   = train_rids,\n",
    "                            labeltime   = timepoint,\n",
    "                            num_classes = num_classes,\n",
    "                            image_shape = image_shape,\n",
    "                            use_pe      = use_pe,\n",
    "                            augmented   = augmented,\n",
    "                            timesteps   = timesteps, \n",
    "                            batch_size  = batch_size,\n",
    "                            drop_last=True,\n",
    "                            shuffle=True)\n",
    "valid_ds = DL.InputFunction(filepath    = data_file,\n",
    "                            list_rids   = valid_rids,\n",
    "                            labeltime   = timepoint,\n",
    "                            num_classes = num_classes,\n",
    "                            image_shape = image_shape,\n",
    "                            use_pe      = use_pe,\n",
    "                            augmented   = augmented,\n",
    "                            timesteps   = timesteps,\n",
    "                            batch_size  = batch_size,\n",
    "                            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcc9562",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = train_ds.steps_per_epoch()\n",
    "if (not train_ds.drop_last) and (train_ds.steps_per_epoch()*batch_size<train_ds.size()):\n",
    "    train_steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e40c603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_time = 0\n",
    "# for i, (feat, label) in enumerate(valid_ds()):\n",
    "#     temp_time = feat['deltas'].shape[1]\n",
    "#     if temp_time > max_time:\n",
    "#         max_time = temp_time\n",
    "# print(max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7823cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, (feat, label) in enumerate(train_ds()):\n",
    "#     if i==0:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ae2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label['conv_lb_neg2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193b16e6",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f831c27",
   "metadata": {},
   "source": [
    "#### Define unimodel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07aebe",
   "metadata": {},
   "source": [
    "##### #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ee423",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    input_name=input_name,\n",
    "    num_classes=num_classes,\n",
    "    num_filters=[4,8,8,16,16],\n",
    "    bap_filters=16,\n",
    "    fc_units=[50, 20],\n",
    "    kernel_size=3,\n",
    "    pool_size=2,\n",
    "    dropout=0.45,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2549b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_model = CLayers.UnimodelS1_CNN_Attention(**model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d852534",
   "metadata": {},
   "source": [
    "## Create trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0982a690",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 3e-3\n",
    "num_epochs    = 50\n",
    "optimizer     = tf.keras.optimizers.Adam(learning_rate=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1c15dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TU.TrainAndEvaluateS1_WSL(\n",
    "    model=uni_model,\n",
    "    model_dir=f\"./checkpoints/unimodel_wsl_{input_name}_{date}_{timepoint}\",\n",
    "    input_name=input_name,\n",
    "    train_dataset=train_ds(),\n",
    "    eval_dataset=valid_ds(),\n",
    "    num_epochs=num_epochs,\n",
    "    train_steps=train_steps,\n",
    "    optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02091740",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainer.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed38e9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('save_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c35d68",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60240de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict_utils as PU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda52fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = PU.Predictor(trainer.model, trainer.model_dir, input_name, augmented=True, ckpt_name='save_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27591554",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ccc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predictor.get_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46724688",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f0b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.plot_confusion_matrix(columns=['Non-Converted', 'Converted', 'AD'], save_path=f'figures/unimodel_wsl_{input_name}_{date}_{timepoint}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8aba8c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
