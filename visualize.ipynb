{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee42a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d226ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "import models as MD\n",
    "\n",
    "from nilearn import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344a54df",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a6739e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fdf433e8",
   "metadata": {},
   "source": [
    "## Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8afc796",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/ADNI_saliency.csv', low_memory=False)\n",
    "date = '20240128_1800'\n",
    "input_name = 'AbsDiff'\n",
    "unique_rids = df['RID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f296d05",
   "metadata": {},
   "source": [
    "### load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a90dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = dict(\n",
    "    enc_filter=16,\n",
    "    gen_filter=16,\n",
    "    dec_filter=16,\n",
    "    dic_filter=16,\n",
    "    enc_dropout=0.3,\n",
    "    dic_dropout=0.3,\n",
    "    latent_dim=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dad1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MD.ProGAN(input_shape=(189,216,189,1), latent_shape=(1024+128,), dicrim_shape=(84,48,42,1))\n",
    "model._make_model(**model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0821d2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = f\"./checkpoints/S2_unimodel_{input_name}_{date}\"\n",
    "save_name = \"epoch_31\"\n",
    "source_dir=\"/ngochuynh/f/Dataset/ADNI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08334df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.E1.load_weights(model_dir+'/'+save_name+'_E1')\n",
    "model.E2.load_weights(model_dir+'/'+save_name+'_E2')\n",
    "model.G1.load_weights(model_dir+'/'+save_name+'_G1')\n",
    "model.De.load_weights(model_dir+'/'+save_name+'_De')\n",
    "model.Di.load_weights(model_dir+'/'+save_name+'_Di')\n",
    "print(f\"Load model weights from {model_dir}/{save_name}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254fa05d",
   "metadata": {},
   "source": [
    "### preprocess input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e24a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_positional_encoding(length_timepoint, channels):\n",
    "    def get_emb(sin_inp):\n",
    "        \"\"\"\n",
    "        Gets a base embedding for one dimension with sin and cos intertwined\n",
    "        \"\"\"\n",
    "        emb = tf.stack((tf.sin(sin_inp), tf.cos(sin_inp)), -1)\n",
    "        emb = tf.reshape(emb, (*emb.shape[:-2], -1))\n",
    "        return emb\n",
    "    \n",
    "    channels = int(np.ceil(channels / 2) * 2)\n",
    "    inv_freq = np.float32(\n",
    "            1\n",
    "            / np.power(\n",
    "                10000, np.arange(0, channels, 2) / np.float32(channels)\n",
    "            )\n",
    "        )\n",
    "    dtype = inv_freq.dtype\n",
    "    pos_x = tf.range(length_timepoint, dtype=dtype)\n",
    "    sin_inp_x = tf.einsum(\"i,j->ij\", pos_x, inv_freq)\n",
    "    emb = tf.expand_dims(get_emb(sin_inp_x), 0)\n",
    "    emb = emb[0]\n",
    "    return emb\n",
    "\n",
    "def normalize_image(image):\n",
    "    return (image - image.min()) / (image.max() -image.min() + 1e-6)\n",
    "\n",
    "def resize(img, new_shape, interpolation=\"nearest\"):\n",
    "    input_shape = np.asarray(img.shape, dtype=np.float16)\n",
    "    ras_image = image.reorder_img(img, resample=interpolation)\n",
    "    output_shape = np.asarray(new_shape)\n",
    "    new_spacing = input_shape/output_shape\n",
    "    new_affine = np.copy(ras_image.affine)\n",
    "    new_affine[:3, :3] = ras_image.affine[:3, :3] * np.diag(new_spacing)\n",
    "    return image.resample_img(ras_image, target_affine=new_affine, target_shape=output_shape, interpolation=interpolation)\n",
    "\n",
    "def crop_region_image(image):\n",
    "    x, y, z = np.where(image != 0)\n",
    "    min_x, max_x = min(x), max(x)\n",
    "    min_y, max_y = min(y), max(y)\n",
    "    min_z, max_z = min(z), max(z)\n",
    "    crop_image = image[min_x:max_x+1, min_y:max_y+1, min_z:max_z+1]\n",
    "    return crop_image, [min_x, max_x, min_y, max_y, min_z, max_z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398f528",
   "metadata": {},
   "outputs": [],
   "source": [
    "ptid = '002_S_0295'\n",
    "sample_id = 0\n",
    "tp_target = [6,12,18,24,30,36,42,48,54,60,72,84,96,108,120]\n",
    "tp_real   = [6,12,30,36,48,60,72]\n",
    "img_normalize = False\n",
    "pos_enc = generate_positional_encoding(150, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b352cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_rows = df[(df['PTID']==ptid) & (df['M']==sample_id)]\n",
    "img_path = selected_rows['MRI_IMG'].tolist()[0]\n",
    "sal_paths = selected_rows['SAL_PATHS'].tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73711763",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe_target = np.zeros((1, 15, 128))\n",
    "for i in range(len(tp_target)):\n",
    "    pe_target[0,i,:] = pos_enc[int(tp_target[i]), :]\n",
    "\n",
    "mri_image = np.zeros((1,189,216,189,1))\n",
    "real_sal_images = np.zeros((1,7,84,48,42,1))\n",
    "\n",
    "img = image.load_img(os.path.join(source_dir,img_path))\n",
    "img = resize(img, (189,216,189))\n",
    "img_data = img.get_fdata()\n",
    "img_data = np.nan_to_num(img_data)\n",
    "if img_normalize:\n",
    "    img_data = normalize_image(img_data)\n",
    "mri_image[0,...,0] = img_data\n",
    "\n",
    "sp = ast.literal_eval(sal_paths)\n",
    "if sp:\n",
    "    heads, tails = zip(*(os.path.split(path) for path in sp))\n",
    "    path_tuples = list(zip(heads, tails))\n",
    "    sorted_path_tuples = sorted(path_tuples, key=lambda x: x[1])\n",
    "    for i, (h, t) in enumerate(sorted_path_tuples):\n",
    "        if input_name==\"AbsDiff\":\n",
    "            sal_img = image.load_img(os.path.join(source_dir, h, t, 'crop_salmap_ad.nii'))\n",
    "        elif input_name==\"MagGrad\":\n",
    "            sal_img = image.load_img(os.path.join(source_dir, h, t, 'crop_salmap_mg.nii'))\n",
    "        elif input_name==\"DirGrad\":\n",
    "            sal_img = image.load_img(os.path.join(source_dir, h, t, 'crop_salmap_dg_1.nii'))\n",
    "        sal_img_resized = resize(sal_img, (84,48,42))\n",
    "        sal_img_resized = np.nan_to_num(sal_img_resized.get_fdata())\n",
    "        if img_normalize:\n",
    "            sal_img_resized = normalize_image(sal_img_resized)\n",
    "        real_sal_images[0,i,...,0] = sal_img_resized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be6a22",
   "metadata": {},
   "source": [
    "### generate saliency maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f32ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_e1 = model.E1(mri_image, training=False)\n",
    "mean_e1, logvar_e1 = model.encode(feat_e1)\n",
    "z_e1 = model.reparameterize(mean_e1, logvar_e1)\n",
    "latent_e1 = tf.concat((z_e1, pe_target[:,0,:]), axis=-1)\n",
    "\n",
    "out_gens = []\n",
    "for i in range(len(tp_target)):\n",
    "    if i==0:\n",
    "        out_gen = model.G1(latent_e1, training=False)\n",
    "    else:\n",
    "        feat_e2 = model.E2(out_gen, training=False)\n",
    "        mean_e2, logvar_e2 = model.encode(feat_e2)\n",
    "        z_e2 = model.reparameterize(mean_e2, logvar_e2)\n",
    "        latent_e2 = tf.concat((z_e1+z_e2, pe_target[:,i,:]), axis=-1)\n",
    "        out_gen = model.G1(latent_e2, training=False)\n",
    "    out_gens.append(out_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a4a419",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_mask = image.load_img(os.path.join(source_dir,'ADNI_saliency',ptid,'Hippocampus','region_mask.nii'))\n",
    "crop_img_mask, _ = crop_region_image(img_mask.get_fdata())\n",
    "crop_img_mask = nib.Nifti1Image(crop_img_mask, img_mask.affine, header=img_mask.header)\n",
    "crop_img_mask = resize(crop_img_mask, (84,48,42))\n",
    "crop_img_mask = np.asarray(crop_img_mask.get_fdata() > 0.5, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1906ec6",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62d3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d.art3d import Poly3DCollection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eef39a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_3d_saliency_grid(saliency_map, output_path, colormap, elevation_angle, azimuthal_angle, roll_angle):\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, subplot_kw={'projection': '3d'})\n",
    "    salient_indices = np.transpose(np.nonzero(saliency_map))\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        sc = ax.scatter(salient_indices[:, 0], salient_indices[:, 1], salient_indices[:, 2],\n",
    "                        c=saliency_map[salient_indices[:, 0], salient_indices[:, 1], salient_indices[:, 2]],\n",
    "                        cmap=colormap, marker='o', alpha=0.5#, vmin=0, vmax=1\n",
    "                        )\n",
    "        ax.set_xlabel('X')\n",
    "        ax.set_ylabel('Y')\n",
    "        ax.set_zlabel('Z')\n",
    "        ax.view_init(elevation_angle[i], azimuthal_angle[i], roll_angle[i])\n",
    "    \n",
    "    fig.colorbar(sc, ax=axes.ravel().tolist(), shrink=0.8, pad=0.1)\n",
    "    fig.savefig(output_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4851e9d5",
   "metadata": {},
   "source": [
    "### real images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bab4219",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormap = cm.get_cmap('jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a707b2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i, tp in enumerate(tp_real):\n",
    "    img_map = real_sal_images[0,i,...,0]\n",
    "    output_path = f\"figures/sal_visualize/real_sal_{date}_{input_name}_{tp}.png\"\n",
    "    visualize_3d_saliency_grid(img_map, output_path, colormap, elevation_angle=[30,210,30,30], azimuthal_angle=[90,90,45,135], roll_angle=[0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb388073",
   "metadata": {},
   "source": [
    "### generated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5673a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tp in enumerate(tp_target):\n",
    "    img_map = out_gens[i][0,...,0].numpy() * crop_img_mask\n",
    "    output_path = f\"figures/sal_visualize/fake_sal_{date}_{input_name}_{tp}.png\"\n",
    "    visualize_3d_saliency_grid(img_map, output_path, colormap, elevation_angle=[30,210,30,30], azimuthal_angle=[90,90,45,135], roll_angle=[0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fa49c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
